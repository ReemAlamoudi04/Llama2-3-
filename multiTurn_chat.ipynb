{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LlamaV2 import llama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing multi-turn prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.together.xyz/v1/chat/completions\n",
      "{'model': 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'prompt': '[INST]what are fun activities i can do this weekend?[/INST]'}\n",
      "{'Authorization': 'Bearer tgp_v1_oNLzGmd3VvxsAAYImTi1MJLDaa1ZTY-L8RVIpwmB1m4', 'Content-Type': 'application/json'}\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"what are fun activities i can do this weekend?\"\n",
    "\n",
    "response1= llama(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.together.xyz/v1/chat/completions\n",
      "{'model': 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'prompt': '[INST]Which of these would be good for my health?[/INST]'}\n",
      "{'Authorization': 'Bearer tgp_v1_oNLzGmd3VvxsAAYImTi1MJLDaa1ZTY-L8RVIpwmB1m4', 'Content-Type': 'application/json'}\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"Which of these would be good for my health?\"\n",
    "\n",
    "response2= llama(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<s>[INST] what are fun activities i can do this weekend? [/INST]\n",
      "<Response [200]>\n",
      "</s>\n",
      "<s>[INST] Which of these would be good for my health? [/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_prompt = f\"\"\"\n",
    "<s>[INST] {prompt1} [/INST]\n",
    "{response1}\n",
    "</s>\n",
    "<s>[INST] {prompt2} [/INST]\n",
    "\"\"\"\n",
    "print(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "\n",
      "<s>[INST] what are fun activities i can do this weekend? [/INST]\n",
      "<Response [200]>\n",
      "</s>\n",
      "<s>[INST] Which of these would be good for my health? [/INST]\n",
      "\n",
      "\n",
      "model: meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
      "https://api.together.xyz/v1/chat/completions\n",
      "{'model': 'meta-llama/Llama-3.3-70B-Instruct-Turbo', 'prompt': '\\n<s>[INST] what are fun activities i can do this weekend? [/INST]\\n<Response [200]>\\n</s>\\n<s>[INST] Which of these would be good for my health? [/INST]\\n'}\n",
      "{'Authorization': 'Bearer tgp_v1_oNLzGmd3VvxsAAYImTi1MJLDaa1ZTY-L8RVIpwmB1m4', 'Content-Type': 'application/json'}\n"
     ]
    }
   ],
   "source": [
    "response_2 = llama(chat_prompt,\n",
    "                 add_inst=False,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LlamaV2 import llama_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [prompt1,prompt2]\n",
    "responses = [response1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "<s>[INST] what are fun activities i can do this weekend? [/INST]\n",
      "<Response [200]>\n",
      " </s><s>[INST] \n",
      "Which of these would be good for my health?\n",
      " [/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n",
      "https://api.together.xyz/v1/chat/completions\n",
      "{'model': 'togethercomputer/llama-2-7b-chat', 'prompt': '<s>[INST] what are fun activities i can do this weekend? [/INST]\\n<Response [200]>\\n </s><s>[INST] \\nWhich of these would be good for my health?\\n [/INST]'}\n",
      "{'Authorization': 'Bearer tgp_v1_oNLzGmd3VvxsAAYImTi1MJLDaa1ZTY-L8RVIpwmB1m4', 'Content-Type': 'application/json'}\n"
     ]
    }
   ],
   "source": [
    "# Pass prompts and responses to llama_chat function\n",
    "response_2 = llama_chat(prompts,responses,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [400]>\n"
     ]
    }
   ],
   "source": [
    "print(response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
